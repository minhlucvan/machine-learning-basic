{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xor resolver using neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a simple `xor` solver using neural network from scrab\n",
    "\n",
    "![](https://i.ytimg.com/vi/yTFc7uCZG5k/maxresdefault.jpg)\n",
    "\n",
    "\n",
    "![](https://i.ytimg.com/vi/kNPGXgzxoHw/maxresdefault.jpg)\n",
    "\n",
    "![](https://www.researchgate.net/profile/Medhat_Moussa/publication/228939274/figure/fig1/AS:393876184551431@1470918808455/Topology-of-ANN-used-to-solve-logic-XOR-problem.png)\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*qA_APGgbbh0QfRNsRyMaJg.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X:\n",
      " \n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "\n",
      "\n",
      "Output Y:\n",
      " \n",
      "[0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# define the inputs\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([0, 1, 1, 0]).T\n",
    "\n",
    "print(\"Input X:\\n \\n{0}\\n\\n\".format(X))\n",
    "print(\"Output Y:\\n \\n{0}\".format(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our input is matrix with 4 rows and 2 columns.\n",
      "size of the hidden layer is 2\n",
      "Leanring rate is 1\n",
      "\n",
      "Initial weights for layer 1 are:\n",
      "[[ 0.41253702  0.43935284]\n",
      " [ 0.30141033  0.19264487]\n",
      " [ 0.29827723  0.82100651]]\n",
      "\n",
      "Initial weights for layer 2 are:\n",
      "[[ 0.80395794]\n",
      " [ 0.61477662]\n",
      " [ 0.97675858]]\n"
     ]
    }
   ],
   "source": [
    "# define hypepramaters\n",
    "\n",
    "m, n = X.shape\n",
    "hidden_size = 2\n",
    "learning_rate = 1\n",
    "number_iteration = 1000\n",
    "\n",
    "weights_1 = np.random.random( (n + 1 , hidden_size))\n",
    "weights_2 = np.random.random( (hidden_size + 1, 1))\n",
    "\n",
    "print(\"Our input is matrix with {0} rows and {1} columns.\".format(m, n))\n",
    "print(\"size of the hidden layer is {0}\".format(hidden_size))\n",
    "print(\"Leanring rate is {0}\".format(learning_rate))  \n",
    "\n",
    "print(\"\\nInitial weights for layer 1 are:\\n{0}\".format(weights_1))\n",
    "\n",
    "print(\"\\nInitial weights for layer 2 are:\\n{0}\".format(weights_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sigmoid\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(y):\n",
    "    return y * (1 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X, weights_1, weights_2):\n",
    "    X_bias_1 = np.c_[np.ones(X.shape[0]), X]\n",
    "    \n",
    "    results_1 = X_bias_1.dot(weights_1)\n",
    "    \n",
    "    activate_values_1 = sigmoid(results_1)\n",
    "    \n",
    "    X_bias_2 =  np.c_[np.ones(X.shape[0]), results_1]\n",
    "    \n",
    "    results_2 = X_bias_2.dot(weights_2)\n",
    "    \n",
    "    activate_values_2 = sigmoid(results_2)\n",
    "    \n",
    "    return results_1, activate_values_1, results_2, activate_values_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results of the layer 1 : \n",
      " [[ 0.41253702  0.43935284]\n",
      " [ 0.71081425  1.26035935]\n",
      " [ 0.71394735  0.63199771]\n",
      " [ 1.01222457  1.45300422]]\n",
      "\n",
      "results of the layer 1 activate function: \n",
      " [[ 0.39830395  0.39189519]\n",
      " [ 0.32941895  0.22091204]\n",
      " [ 0.32872721  0.3470577 ]\n",
      " [ 0.26654472  0.18953964]]\n",
      "\n",
      "results of the layer 2 : \n",
      " [[ 1.48671771]\n",
      " [ 2.47201672]\n",
      " [ 1.86018526]\n",
      " [ 2.84548428]]\n",
      "\n",
      "\n",
      "results of the layer 2 activate function: \n",
      " [[ 0.18441489]\n",
      " [ 0.07784334]\n",
      " [ 0.13468146]\n",
      " [ 0.05491521]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_1, activate_values_1, results_2, activate_values_2   = feed_forward(X, weights_1, weights_2)\n",
    "\n",
    "print(\"results of the layer 1 : \\n {0}\\n\".format(results_1))\n",
    "print(\"results of the layer 1 activate function: \\n {0}\\n\".format(activate_values_1))\n",
    "\n",
    "print(\"results of the layer 2 : \\n {0}\\n\\n\".format(results_2))\n",
    "print(\"results of the layer 2 activate function: \\n {0}\\n\\n\".format(activate_values_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(X, Y, weights_1, weights_2, lraning_rate, number_iteration):\n",
    "    \n",
    "    current_weights_1 = weights_1\n",
    "    current_weights_2 = weights_2\n",
    "    \n",
    "    for i in range(number_iteration):\n",
    "        h1, alpha1, h2, alpha2 = feed_forward(\n",
    "            X,\n",
    "            current_weights_1,\n",
    "            current_weights_2\n",
    "        )\n",
    "        # loss fn = MSE\n",
    "        t = np.array([Y]).T\n",
    "        \n",
    "        e2 = (h2 - t) / X.shape[1]\n",
    "        \n",
    "        dw2 = np.dot(sigmoid_grad(alpha2), e2.T)\n",
    "        \n",
    "        e1 = np.dot(dw2, current_weights_1)\n",
    "        \n",
    "        dw1 = np.dot(sigmoid_grad(alpha), e1.T )\n",
    "        \n",
    "        layer1_adjustment = X.T.dot(dw1)\n",
    "        layer2_adjustment = Y.T.dot(dw2)\n",
    "        \n",
    "        current_weights_2 += (lraning_rate * layer2_adjustment)\n",
    "        current_weights_1 += (lraning_rate * layer1_adjustment)\n",
    "        \n",
    "    return current_weights_1, current_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,4) and (3,2) not aligned: 4 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-94081731772c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mweights_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnumber_iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-0b59d745bcaf>\u001b[0m in \u001b[0;36mback_propagation\u001b[0;34m(X, Y, weights_1, weights_2, lraning_rate, number_iteration)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_weights_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,4) and (3,2) not aligned: 4 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "final_weights_1, final_wights_2 = back_propagation(\n",
    "    X,\n",
    "    Y,\n",
    "    weights_1,\n",
    "    weights_2,\n",
    "    learning_rate,\n",
    "    number_iteration\n",
    ")\n",
    "\n",
    "\n",
    "print(\"the errors_graph: \\n {0}\\n\".format(errors_graph))\n",
    "print(\"the final weights of layer 1: \\n {0}\\n\".format(final_weights_1))\n",
    "print(\"the final weights of layer 2: \\n {0}\\n\".format(final_wights_2))\n",
    "\n",
    "\n",
    "_, _, _, _, predicted_values = feed_forward(X, final_weights_1, final_wights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://chrisjmccormick.files.wordpress.com/2014/03/gradientdescentofmsetable.png)\n",
    "[https://www.slideshare.net/Jboulie/ann-preso-draft](https://www.slideshare.net/Jboulie/ann-preso-draft)\n",
    "\n",
    "[http://mccormickml.com/2014/03/04/gradient-descent-derivation/](http://mccormickml.com/2014/03/04/gradient-descent-derivation/)\n",
    "\n",
    "[https://iamtrask.github.io/2015/07/27/python-network-part2/](https://iamtrask.github.io/2015/07/27/python-network-part2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
